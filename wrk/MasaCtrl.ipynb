{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## MasaCtrl: Tuning-free <span style=\"text-decoration: underline\"><font color=\"Tomato\">M</font></span>utu<span style=\"text-decoration: underline\"><font color=\"Tomato\">a</font></span>l <span style=\"text-decoration: underline\"><font color=\"Tomato\">S</font></span>elf-<span style=\"text-decoration: underline\"><font color=\"Tomato\">A</font></span>ttention <span style=\"text-decoration: underline\"><font color=\"Tomato\">Control</font></span> for Consistent Image Synthesis and Editing\n",
        "\n",
        "Pytorch implementation of [MasaCtrl: Tuning-free Mutual Self-Attention Control for **Consistent Image Synthesis and Editing**](https://arxiv.org/abs/2304.08465)\n",
        "\n",
        "[Mingdeng Cao](https://github.com/ljzycmd),\n",
        "[Xintao Wang](https://xinntao.github.io/),\n",
        "[Zhongang Qi](https://scholar.google.com/citations?user=zJvrrusAAAAJ),\n",
        "[Ying Shan](https://scholar.google.com/citations?user=4oXBp9UAAAAJ),\n",
        "[Xiaohu Qie](https://scholar.google.com/citations?user=mk-F69UAAAAJ),\n",
        "[Yinqiang Zheng](https://scholar.google.com/citations?user=JD-5DKcAAAAJ)\n",
        "\n",
        "[![arXiv](https://img.shields.io/badge/ArXiv-2304.08465-brightgreen)](https://arxiv.org/abs/2304.08465)\n",
        "[![Project page](https://img.shields.io/badge/Project-Page-brightgreen)](https://ljzycmd.github.io/projects/MasaCtrl/)\n",
        "[![demo](https://img.shields.io/badge/Demo-Hugging%20Face-brightgreen)](https://huggingface.co/spaces/TencentARC/MasaCtrl)\n",
        "\n",
        "---\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://huggingface.co/TencentARC/MasaCtrl/resolve/main/assets/overview.png\">\n",
        "<i> MasaCtrl enables performing various consistent non-rigid image synthesis and editing without fine-tuning and optimization. </i>\n",
        "</div>"
      ],
      "metadata": {
        "id": "MjYwyTwXL9VC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnpa3VncL6Zm",
        "outputId": "5e426a4a-b8d7-4560-a291-9dcc0ce76398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/TencentARC/MasaCtrl.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xfzmjwNMJ_q",
        "outputId": "e8dc01e9-0973-4cbb-92d4-f0f72c526f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MasaCtrl' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MasaCtrl\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSUue7nUMX4G",
        "outputId": "1782e5f3-fa78-4018-d4a2-cd6b31f8e5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MasaCtrl\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: diffusers==0.15.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.29.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.7.0.72)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0->-r requirements.txt (line 1)) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0->-r requirements.txt (line 1)) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0->-r requirements.txt (line 1)) (0.14.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0->-r requirements.txt (line 1)) (6.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0->-r requirements.txt (line 1)) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0->-r requirements.txt (line 1)) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (4.65.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf->-r requirements.txt (line 5)) (4.9.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning->-r requirements.txt (line 6)) (2.0.0+cu118)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning->-r requirements.txt (line 6)) (2023.4.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning->-r requirements.txt (line 6)) (0.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning->-r requirements.txt (line 6)) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning->-r requirements.txt (line 6)) (0.8.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 6)) (3.8.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning->-r requirements.txt (line 6)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning->-r requirements.txt (line 6)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning->-r requirements.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning->-r requirements.txt (line 6)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning->-r requirements.txt (line 6)) (16.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.15.0->-r requirements.txt (line 1)) (3.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.15.0->-r requirements.txt (line 1)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.15.0->-r requirements.txt (line 1)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.15.0->-r requirements.txt (line 1)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.15.0->-r requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 6)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 6)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 6)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 6)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch_lightning->-r requirements.txt (line 6)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch_lightning->-r requirements.txt (line 6)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from einops import rearrange, repeat\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "from diffusers import DDIMScheduler\n",
        "\n",
        "from masactrl.diffuser_utils import MasaCtrlPipeline\n",
        "from masactrl.masactrl_utils import AttentionBase\n",
        "from masactrl.masactrl_utils import regiter_attention_editor_diffusers\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.io import read_image\n",
        "from pytorch_lightning import seed_everything\n",
        "\n",
        "torch.cuda.set_device(0)  # set the GPU device"
      ],
      "metadata": {
        "id": "b65EiID6MkE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Construction"
      ],
      "metadata": {
        "id": "WkkhevXTPRVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that you may add your Hugging Face token to get access to the models\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model_path = \"andite/anything-v4.0\"\n",
        "# model_path = \"runwayml/stable-diffusion-v1-5\"\n",
        "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "model = MasaCtrlPipeline.from_pretrained(model_path, scheduler=scheduler).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxdsHwYENJCx",
        "outputId": "13a4c741-868b-4fbe-8749-32e4b3ba7713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Keyword arguments {'cross_attention_kwargs': {'scale': 0.5}} are not expected by MasaCtrlPipeline and will be ignored.\n",
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:107: FutureWarning: The configuration file of this scheduler: DDIMScheduler {\n",
            "  \"_class_name\": \"DDIMScheduler\",\n",
            "  \"_diffusers_version\": \"0.15.0\",\n",
            "  \"beta_end\": 0.012,\n",
            "  \"beta_schedule\": \"scaled_linear\",\n",
            "  \"beta_start\": 0.00085,\n",
            "  \"clip_sample\": false,\n",
            "  \"clip_sample_range\": 1.0,\n",
            "  \"dynamic_thresholding_ratio\": 0.995,\n",
            "  \"num_train_timesteps\": 1000,\n",
            "  \"prediction_type\": \"epsilon\",\n",
            "  \"sample_max_value\": 1.0,\n",
            "  \"set_alpha_to_one\": false,\n",
            "  \"steps_offset\": 0,\n",
            "  \"thresholding\": false,\n",
            "  \"trained_betas\": null\n",
            "}\n",
            " is outdated. `steps_offset` should be set to 1 instead of 0. Please make sure to update the config accordingly as leaving `steps_offset` might led to incorrect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for the `scheduler/scheduler_config.json` file\n",
            "  deprecate(\"steps_offset!=1\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Consistent synthesis with MasaCtrl"
      ],
      "metadata": {
        "id": "kGqCKysSPzcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from masactrl.masactrl import MutualSelfAttentionControl\n",
        "\n",
        "\n",
        "seed = 42\n",
        "seed_everything(seed)\n",
        "\n",
        "out_dir = \"./workdir/masactrl_exp/\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "sample_count = len(os.listdir(out_dir))\n",
        "out_dir = os.path.join(out_dir, f\"sample_{sample_count}\")\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "prompts = [\n",
        "    \"1boy, casual, outdoors, sitting\",  # source prompt\n",
        "    \"1boy, casual, outdoors, standing\"  # target prompt\n",
        "]\n",
        "\n",
        "# initialize the noise map\n",
        "start_code = torch.randn([1, 4, 64, 64], device=device)\n",
        "start_code = start_code.expand(len(prompts), -1, -1, -1)\n",
        "\n",
        "# inference the synthesized image without MasaCtrl\n",
        "editor = AttentionBase()\n",
        "regiter_attention_editor_diffusers(model, editor)\n",
        "image_ori = model(prompts, latents=start_code, guidance_scale=7.5).cpu()\n",
        "\n",
        "# inference the synthesized image with MasaCtrl\n",
        "STEP = 4\n",
        "LAYPER = 10\n",
        "\n",
        "# hijack the attention module\n",
        "editor = MutualSelfAttentionControl(STEP, LAYPER)\n",
        "regiter_attention_editor_diffusers(model, editor)\n",
        "\n",
        "# inference the synthesized image\n",
        "image_masactrl = model(prompts, latents=start_code, guidance_scale=7.5)[-1:].cpu()\n",
        "\n",
        "# save the synthesized image\n",
        "out_image = torch.cat([image_ori, image_masactrl], dim=0)\n",
        "save_image(out_image, os.path.join(out_dir, f\"all_step{STEP}_layer{LAYPER}.png\"))\n",
        "save_image(out_image[0], os.path.join(out_dir, f\"source_step{STEP}_layer{LAYPER}.png\"))\n",
        "save_image(out_image[1], os.path.join(out_dir, f\"without_step{STEP}_layer{LAYPER}.png\"))\n",
        "save_image(out_image[2], os.path.join(out_dir, f\"masactrl_step{STEP}_layer{LAYPER}.png\"))\n",
        "\n",
        "print(\"Syntheiszed images are saved in\", out_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX8ZQYxwPU68",
        "outputId": "dd68dea2-8747-4690-9a53-b4eac8d33656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/models/unet_2d_condition.py:452: FutureWarning: Accessing `in_channels` directly via unet.in_channels is deprecated. Please use `unet.config.in_channels` instead\n",
            "  deprecate(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input text embeddings : torch.Size([2, 77, 768])\n",
            "latents shape:  torch.Size([2, 4, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 50/50 [00:56<00:00,  1.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step_idx:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "layer_idx:  [10, 11, 12, 13, 14, 15]\n",
            "input text embeddings : torch.Size([2, 77, 768])\n",
            "latents shape:  torch.Size([2, 4, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 50/50 [01:01<00:00,  1.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syntheiszed images are saved in ./workdir/masactrl_exp/sample_2\n"
          ]
        }
      ]
    }
  ]
}