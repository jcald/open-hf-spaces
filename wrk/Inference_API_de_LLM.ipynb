{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-xUmcqkUf9Dv",
        "rAUWqtMgNuFn",
        "wQGYW35vCk6m",
        "UhauDrynY0cj",
        "u34Eduf2UKv6",
        "Xf4SMfT0LaHA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Despliegue de LLM\n",
        "\n"
      ],
      "metadata": {
        "id": "dpL2NjDCW4KH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9fJuC2tG0Cq"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain huggingface_hub transformers sentence_transformers accelerate bitsandbytes python_dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Pipeline Local (descargamos el modelo)\n"
      ],
      "metadata": {
        "id": "-xUmcqkUf9Dv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A - HuggingFace - Transformers"
      ],
      "metadata": {
        "id": "rAUWqtMgNuFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "_mG4_RfL6Ojd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargamos el modelo\n",
        "# google/flan-t5-small\n",
        "model_id = 'google/flan-t5-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id,\n",
        "                                              load_in_8bit=True,\n",
        "                                              device_map='auto')"
      ],
      "metadata": {
        "id": "GMg2xiRnfm21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_generator = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=128\n",
        ")"
      ],
      "metadata": {
        "id": "zlq5wAPu6XPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_generator(\"In which country is madrid? Let's think step by step\")"
      ],
      "metadata": {
        "id": "pCbrJucH8lea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_generator('Create an email for my boss requesting vacations')"
      ],
      "metadata": {
        "id": "B0YZxRMf9bu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### B - Langchain"
      ],
      "metadata": {
        "id": "wQGYW35vCk6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "local_llm = HuggingFacePipeline(pipeline=model_generator)\n",
        "print(local_llm(\"In which country is madrid? Let's think step by step\"))"
      ],
      "metadata": {
        "id": "MuuPU4HY8fdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_llm('Create an email for my boss requesting vacations')"
      ],
      "metadata": {
        "id": "LvsLFQxehfZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Inference API"
      ],
      "metadata": {
        "id": "UhauDrynY0cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "M2AxZrt1Cyl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'HUGGINGFACEHUB_API_TOKEN'"
      ],
      "metadata": {
        "id": "LMlAI7zYCW_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A - HuggingFace"
      ],
      "metadata": {
        "id": "u34Eduf2UKv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub.inference_api import InferenceApi\n",
        "\n",
        "model_api = InferenceApi(\n",
        "    repo_id='google/flan-t5-large',\n",
        "    token=os.environ['HUGGINGFACEHUB_API_TOKEN']\n",
        ")"
      ],
      "metadata": {
        "id": "d7ZoKIE6Ap8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = \"What is the capital of Spain?\"\n",
        "\n",
        "prompt = f\"\"\"Question: {pregunta}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\""
      ],
      "metadata": {
        "id": "nfM7hPH5B6tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "id": "gJFadY-bB8wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_api(prompt)"
      ],
      "metadata": {
        "id": "9q8x4RHhBpz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### B - Langchain"
      ],
      "metadata": {
        "id": "Xf4SMfT0LaHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
        "\n",
        "plantilla = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=plantilla, input_variables=[\"question\"])"
      ],
      "metadata": {
        "id": "Derb_0t-ZESh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt,\n",
        "                     llm=HuggingFaceHub(repo_id=\"google/flan-t5-large\",\n",
        "                                        model_kwargs={\"temperature\":0,\n",
        "                                                      \"max_length\":128}))"
      ],
      "metadata": {
        "id": "lvO31GCGKhHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the capital of Spain?\"\n",
        "\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "id": "uWIc38V4t5gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"what is the answer to life the universe and everything?\"\n",
        "\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "id": "uK61DssCdCmr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}