{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6BV616dtWApv",
        "GWyP01zgMI3r",
        "UsXcwx9MMDd7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 0 - Configuración"
      ],
      "metadata": {
        "id": "6BV616dtWApv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sagemaker python-dotenv --quiet"
      ],
      "metadata": {
        "id": "05hMgR3hD2NJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9b869a-8ae9-4d3a-aa9c-3cad74bc32b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/844.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.5/844.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m844.7/844.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.9/135.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sagemaker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for protobuf3-to-dict (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sagemaker\n",
        "import boto3\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "S-jarnrCZslB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 - Sesión AWS"
      ],
      "metadata": {
        "id": "GWyP01zgMI3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# variables de entorno\n",
        "# Opción 1\n",
        "# os.environ[\"aws_access_key_id\"]='aws_access_key_id'\n",
        "# os.environ[\"aws_secret_access_key\"]='aws_secret_access_key'\n",
        "\n",
        "# Opción 2\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG6fZtY3DtGZ",
        "outputId": "d1d43b74-aebd-4da2-ede7-1c5f1ab3dede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  [Secret keys](https://docs.aws.amazon.com/powershell/latest/userguide/pstools-appendix-sign-up.html)"
      ],
      "metadata": {
        "id": "gHKSkn3jcxcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REGION_NAME = \"us-east-1\"\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = REGION_NAME\n",
        "ROLE_NAME =  'Sagemaker-ExecutionRole'\n",
        "\n",
        "auth_arguments = {\n",
        "    'aws_access_key_id':os.environ[\"aws_access_key_id\"],\n",
        "    'aws_secret_access_key':os.environ[\"aws_secret_access_key\"],\n",
        "    'region_name':REGION_NAME\n",
        "}"
      ],
      "metadata": {
        "id": "7lQjG0DGPwKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[IAM rol](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)"
      ],
      "metadata": {
        "id": "pDJJRkX7EMPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iam = boto3.client('iam', **auth_arguments)\n",
        "role = iam.get_role(RoleName=ROLE_NAME)['Role']['Arn']\n",
        "\n",
        "session = sagemaker.Session(boto3.Session(**auth_arguments))"
      ],
      "metadata": {
        "id": "geOptch-Ep-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 - Despliegue"
      ],
      "metadata": {
        "id": "UsXcwx9MMDd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
        "\n",
        "# image uri\n",
        "llm_image = get_huggingface_llm_image_uri(\"huggingface\")\n",
        "\n",
        "print(f\"image uri: {llm_image}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVUJhmZ0EOja",
        "outputId": "1e8d0bf4-97fd-4efe-a9a2-6bf393ac7d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.0-tgi0.8.2-gpu-py39-cu118-ubuntu20.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.huggingface import HuggingFaceModel\n",
        "\n",
        "# Falcon 7b\n",
        "hub = {'HF_MODEL_ID':'tiiuae/falcon-7b'}\n",
        "\n",
        "# Hugging Face Model Class\n",
        "huggingface_model = HuggingFaceModel(\n",
        "   env=hub,\n",
        "   role=role,  # iam role from AWS\n",
        "   image_uri=llm_image,\n",
        "   sagemaker_session=session\n",
        ")"
      ],
      "metadata": {
        "id": "ZaWhGsUy3Cb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deploy model to SageMaker\n",
        "predictor = huggingface_model.deploy(\n",
        "\tinitial_instance_count=1, # number of instances\n",
        "\tinstance_type='ml.g5.2xlarge', #'ml.g5.4xlarge'\n",
        " \tcontainer_startup_health_check_timeout=300\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEWp5OSEGuEl",
        "outputId": "835fb5b6-b731-4bfa-898a-b7ef6051d6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 - Inferencia"
      ],
      "metadata": {
        "id": "ouZf5rK8L6Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define prompt\n",
        "prompt = \"\"\"You are the most advanced AI assistant on the planet, called Falcon.\n",
        "\n",
        "User: What is the capital of Spain? Think step by step.\n",
        "Falcon:\"\"\"\n",
        "\n",
        "# hyperparameters for llm\n",
        "request = {\n",
        "  \"inputs\": prompt,\n",
        "  \"parameters\": {\n",
        "    \"do_sample\": True,\n",
        "    \"top_p\": 0.9,\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_new_tokens\": 512,\n",
        "    \"stop\": [\"\\nUser:\",\"<|endoftext|>\",\"</s>\"]\n",
        "  }\n",
        "}\n",
        "\n",
        "# request to endpoint\n",
        "response = predictor.predict(request)\n",
        "\n",
        "# model response\n",
        "assistant = response[0][\"generated_text\"][len(prompt):]"
      ],
      "metadata": {
        "id": "1E8NHDnN0OI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(assistant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lNOJoaf3Dtv",
        "outputId": "93144c43-097f-4c9f-f498-b53670c88489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The capital of Spain is Madrid.\n",
            "User:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BORRAR ENDPOINT para evitar gastos innecesarios\n",
        "predictor.delete_model()\n",
        "predictor.delete_endpoint()"
      ],
      "metadata": {
        "id": "NieX7MHHdhCQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}